{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ***In this notebook , We will not follow common way of predicting from just pretrained model , instead we will take features of image by predicting image with second last layer of pretrained model and then fit it again with xgboost and get final predictions.***"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/hackereath-holiday-season-deep-learning-contest/dataset/train.csv')\ndf.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"           Image          Class\n0  image3476.jpg  Miscellaneous\n1  image5198.jpg         Candle\n2  image4183.jpg        Snowman\n3  image1806.jpg  Miscellaneous\n4  image7831.jpg  Miscellaneous","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>image3476.jpg</td>\n      <td>Miscellaneous</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>image5198.jpg</td>\n      <td>Candle</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>image4183.jpg</td>\n      <td>Snowman</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>image1806.jpg</td>\n      <td>Miscellaneous</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>image7831.jpg</td>\n      <td>Miscellaneous</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.inception_v3 import InceptionV3,preprocess_input","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n        preprocessing_function=preprocess_input)","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ***Using flow from dataframe method for mapping dataframe and directory both.***"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = datagen.flow_from_dataframe(\n    df,\n    directory='../input/hackereath-holiday-season-deep-learning-contest/dataset/train',\n    x_col = 'Image',\n    y_col = 'Class',\n    target_size=(299,299),\n    class_mode = 'categorical',\n    batch_size=32)","execution_count":6,"outputs":[{"output_type":"stream","text":"Found 6469 validated image filenames belonging to 6 classes.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# ***Using InceptionV3 pretrained model. You can try with others also.***"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = InceptionV3(include_top=False,weights='imagenet',input_shape=(299,299,3))","execution_count":7,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n87916544/87910968 [==============================] - 1s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = False","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers,models","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ***Adding some extra layers over pretrained model.***"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(base_model)\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.Dense(512,activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(256,activation='relu'))\nmodel.add(layers.Dense(6,activation='softmax'))","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss = 'categorical_crossentropy',\n    metrics = ['accuracy'])","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_steps = np.ceil(train_generator.n/train_generator.batch_size)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(\n    train_generator,\n    epochs=12,\n    batch_size=32,\n    steps_per_epoch=train_steps)","execution_count":13,"outputs":[{"output_type":"stream","text":"Epoch 1/12\n203/203 [==============================] - 51s 249ms/step - loss: 0.6055 - accuracy: 0.7922\nEpoch 2/12\n203/203 [==============================] - 25s 125ms/step - loss: 0.3866 - accuracy: 0.8626\nEpoch 3/12\n203/203 [==============================] - 25s 123ms/step - loss: 0.3321 - accuracy: 0.8821\nEpoch 4/12\n203/203 [==============================] - 24s 120ms/step - loss: 0.2998 - accuracy: 0.8970\nEpoch 5/12\n203/203 [==============================] - 25s 121ms/step - loss: 0.2674 - accuracy: 0.9072\nEpoch 6/12\n203/203 [==============================] - 25s 121ms/step - loss: 0.2509 - accuracy: 0.9108\nEpoch 7/12\n203/203 [==============================] - 25s 122ms/step - loss: 0.2423 - accuracy: 0.9128\nEpoch 8/12\n203/203 [==============================] - 25s 122ms/step - loss: 0.2234 - accuracy: 0.9233\nEpoch 9/12\n203/203 [==============================] - 24s 120ms/step - loss: 0.2106 - accuracy: 0.9222\nEpoch 10/12\n203/203 [==============================] - 25s 122ms/step - loss: 0.2003 - accuracy: 0.9246\nEpoch 11/12\n203/203 [==============================] - 25s 123ms/step - loss: 0.1985 - accuracy: 0.9277\nEpoch 12/12\n203/203 [==============================] - 25s 121ms/step - loss: 0.1869 - accuracy: 0.9311\n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f8ae04e7150>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# ***Crucial step : Generated features of imagesby predicting it by removing the last layer of the model.***"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nnew_train_x = []\nnew_train_y = []\nmodel2 = keras.Model(model.input, model.layers[-5].output)\ncount = 0\nwhile count < 200:\n    x_batch,y_batch = next(train_generator)\n    pred = model2.predict(x_batch)\n    new_train_x.extend(pred)\n    new_train_y.extend(y_batch)\n    count += 1\n","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train_y = np.argmax(new_train_y,axis=1)\nprint(new_train_y.shape)","execution_count":15,"outputs":[{"output_type":"stream","text":"(6400,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train_x = np.array(new_train_x)\nnew_train_y = np.array(new_train_y)\nprint(new_train_x.shape)\nprint(new_train_y.shape)","execution_count":16,"outputs":[{"output_type":"stream","text":"(6400, 2048)\n(6400,)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# ***Fitting new_train_x and new_train_y with xgboost.***"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nclf = XGBClassifier(max_depth=7, objective='multi:softmax', n_estimators=1000, \n                        num_classes=6)\nclf.fit(new_train_x,new_train_y)","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.300000012, max_delta_step=0, max_depth=10,\n              min_child_weight=1, missing=nan, monotone_constraints='()',\n              n_estimators=1000, n_jobs=0, num_parallel_tree=1,\n              objective='multi:softprob', random_state=0, reg_alpha=0,\n              reg_lambda=1, scale_pos_weight=None, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.DataFrame()\ntest_images = os.listdir('../input/hackereath-holiday-season-deep-learning-contest/dataset/test')\ntest_df['Image']=test_images\ntest_df.head()","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"           Image\n0  image7761.jpg\n1  image3202.jpg\n2   image688.jpg\n3   image233.jpg\n4  image4332.jpg","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>image7761.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>image3202.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>image688.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>image233.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>image4332.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# ***Preparing test generator***"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator = datagen.flow_from_dataframe(\n    test_df,\n    directory='../input/hackereath-holiday-season-deep-learning-contest/dataset/test',\n    x_col = 'Image',\n    y_col = None,\n    target_size=(299,299),\n    class_mode = None,\n    batch_size=32,\n    shuffle = False)","execution_count":19,"outputs":[{"output_type":"stream","text":"Found 3489 validated image filenames.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# ***Predicting on test_generator***"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_test_x = model2.predict(test_generator)\nnew_test_x = np.array(new_test_x)\npredictions_xgb = clf.predict(new_test_x)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_xgb","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"array([4, 4, 5, ..., 4, 4, 4])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['Class']=predictions_xgb","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_to_class = dict((y,x) for (x,y) in train_generator.class_indices.items())\nnum_to_class","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"{0: 'Airplane',\n 1: 'Candle',\n 2: 'Christmas_Tree',\n 3: 'Jacket',\n 4: 'Miscellaneous',\n 5: 'Snowman'}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['Class']=test_df['Class'].map(num_to_class)\ntest_df.head()","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"           Image           Class\n0  image7761.jpg   Miscellaneous\n1  image3202.jpg   Miscellaneous\n2   image688.jpg         Snowman\n3   image233.jpg          Candle\n4  image4332.jpg  Christmas_Tree","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>image7761.jpg</td>\n      <td>Miscellaneous</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>image3202.jpg</td>\n      <td>Miscellaneous</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>image688.jpg</td>\n      <td>Snowman</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>image233.jpg</td>\n      <td>Candle</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>image4332.jpg</td>\n      <td>Christmas_Tree</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.to_csv('pred.csv',index=False)","execution_count":25,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ***If you have any doubts in above code , please ask in the comment section. I will surely revert back as soon as possible***"},{"metadata":{},"cell_type":"markdown","source":"# ***If you find the notebook informative , please drop a like***"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}